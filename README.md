[中文](./README_cn.md)

## Overview

FlagOS-Robo is built upon the open-source multi-chip AI software stack [FlagOS](https://flagos.io).
It serves as an integrated training and inference framework for embodied intelligence.
It can be deployed across diverse scenarios ranging from edge to clouds.
Being portable across various chip models, it enables efficient collaborative training and inference
between Vision Language Models (VLMs) and Vision Language Action (VLA) models.
FlagOS-Robo helps piping data from the data collection end to real-machine and the FlagEval platform
for testing and evaluation. It has been deeply integrated into BAAI’s embodied intelligence platform.
FlagOS-Robo provides a powerful computational foundation and systematic support for cutting-edge researches
and industrial applications in embodied intelligence, accelerating innovations and real-world deployments
of intelligent agents.

## Feature Highlights

- FlagOS-Robo enables efficient cross-chip training and inference for both VLM and VLA models
  through the FlagOS software stack, supporting diverse cloud server chips and edge devices.

- It covers the full process of training and inference deployment for the RoboBrain (VLM) and
  Robotics (VLA) models, offering a simple and user-friendly interface with adaptive optimization
  and one-click deployment.

- FlagOS-Robo supports [RoboOS](https://github.com/FlagOpen/RoboOS)-based cross-embodiment collaboration,
  ensuring compatibility with different data formats, efficient edge-cloud coordination,
  and real-machine evaluation.
